{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"output\":\"This is a dummy output\",\"status\":\"success\"}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "url = \"https://genloopv1.uc.r.appspot.com/model_inference\"\n",
    "\n",
    "payload = json.dumps({\n",
    "  \"model\": \"sring\",\n",
    "  \"messages\": [],\n",
    "  \"stream\": True,\n",
    "  \"meta\": \"\"\n",
    "})\n",
    "\n",
    "\n",
    "response = requests.request(\"POST\", url, data=payload)\n",
    "\n",
    "print(response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlalchemy\n",
    "def connect_tcp_socket() -> sqlalchemy.engine.base.Engine:\n",
    "    \"\"\"Initializes a TCP connection pool for a Cloud SQL instance of Postgres.\"\"\"\n",
    "\n",
    "    pool = sqlalchemy.create_engine(\n",
    "        # Equivalent URL:\n",
    "        # url = 'genloopv1:us-central1:genloop-postgresv1'\n",
    "        # url = 'postgresql+psycopg2://postgres:genloop@123@34.68.9.168:5302/postgresv1'\n",
    "        sqlalchemy.engine.url.URL.create(\n",
    "            drivername=\"postgresql+psycopg2\",\n",
    "            username = \"postgres\",\n",
    "            password='genloop@123', #TODO pick from env\n",
    "            host='34.68.9.168', #TODO pick from env\n",
    "            port='5432',\n",
    "            database='postgres',\n",
    "        )\n",
    "    )\n",
    "    return pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insert successful!\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import text\n",
    "\n",
    "engine = connect_tcp_socket()\n",
    "\n",
    "# query = f\"\"\"\n",
    "# INSERT INTO dataset_hub (dataset_id, dataset_name, created_at, rows, model_ids, project_id)\n",
    "# VALUES (temp, value2, 2024-02-20T00:00:00Z, 1, [\"model\"], \"PROJEct1\");\n",
    "\n",
    "# \"\"\"\n",
    "\n",
    "# result = connection.execute(query)\n",
    "\n",
    "# return [row[0] for row in result]\n",
    "\n",
    "with engine.connect() as connection:\n",
    "    connection.execution_options(isolation_level=\"AUTOCOMMIT\")    \n",
    "    query = text(\"\"\"\n",
    "        INSERT INTO public.dataset_hub (dataset_id, dataset_name, created_at, rows, model_ids, project_id)\n",
    "        VALUES (:dataset_id, :dataset_name, :created_at, :rows, :model_ids, :project_id);\n",
    "        \"\"\")\n",
    "        \n",
    "    connection.execute(query, {\n",
    "            'dataset_id': 'test',\n",
    "            'dataset_name': 'value2',\n",
    "            'created_at': '2024-02-20T00:00:00Z',  # Correctly quoted timestamp\n",
    "            'rows': 1,\n",
    "            'model_ids': '{}',  # Properly formatted array\n",
    "            'project_id': 'PROJECT1'\n",
    "    })\n",
    "    if result.rowcount > 0:\n",
    "            print(\"Insert successful!\")\n",
    "    else:\n",
    "            print(\"Insert failed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Data01', 'Records until Feb 20 2024', 'GPT4 records until Feb 20, 2024', datetime.datetime(2024, 2, 20, 0, 0), 15000, ['modelA', 'modelB', 'modelC'], {'parent': None, 'version': 1}, '/datasets/records_feb_20_2024', 'PROJ001')\n",
      "('Data02', 'Records until Aug 3 2024', 'Product records until Aug 3, merged with Data01', datetime.datetime(2024, 8, 3, 0, 0), 143800, ['modelA', 'modelB', 'modelC'], {'parent': 'Data01', 'version': 2}, '/datasets/records_aug_3_2024', 'PROJ001')\n",
      "('Data03', 'Q1 2024 Customer Feedback', 'Customer feedback analysis for Q1 2024', datetime.datetime(2024, 4, 1, 0, 0), 50000, ['modelA', 'modelB', 'modelC'], {'parent': None, 'version': 1}, '/datasets/customer_feedback_q1_2024', 'PROJ001')\n",
      "('Data04', 'Sales Forecast 2024', 'Annual sales forecast dataset', datetime.datetime(2024, 1, 15, 0, 0), 10000, ['modelA', 'modelB', 'modelC'], {'parent': None, 'version': 1}, '/datasets/sales_forecast_2024', 'PROJ001')\n",
      "('Data05', 'Sales Forecast 2024 - Updated', 'Updated annual sales forecast with Q1 data', datetime.datetime(2024, 4, 10, 0, 0), 12500, ['modelA', 'modelB', 'modelC'], {'parent': 'Data04', 'version': 2}, '/datasets/sales_forecast_2024_v2', 'PROJ001')\n",
      "('temp', 'value2', None, datetime.datetime(2024, 2, 20, 0, 0), 1, ['model'], None, None, 'PROJECT1')\n"
     ]
    }
   ],
   "source": [
    " with engine.connect() as connection:\n",
    "        result = connection.execute(text(\"SELECT * FROM public.dataset_hub;\"))\n",
    "        for row in result:\n",
    "            print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple Discontinues IP-Home Sales in China\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "openai_api_key = \"BW8J_qlpGFAD51VXihUoNAHxsyN1jXkvQLsMf4nueHI\"\n",
    "openai_api_base = \"http://34.122.194.201:8000/v1\" \n",
    "\n",
    "client = OpenAI(\n",
    "    base_url=openai_api_base,\n",
    "    api_key=openai_api_key\n",
    ")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model = \"genloop/fin-news-headline-gen_mistral-nemo-instruct-merged\",\n",
    "  messages = [ \n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": \"Generate a suitable headline for given input of a financial news article. Only output the headline not the instruction and input texts.\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"apple discontinues iphone sales in china. it has shut down all the factories\"\n",
    "    }\n",
    "  ],\n",
    "  max_tokens = 85,\n",
    "  temperature = 0.7,\n",
    "  stream = False\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[11:12 PM, 9/23/2024] Eshan Gujar Genloop: openai_api_key = \"BW8J_qlpGFAD51VXihUoNAHxsyN1jXkvQLsMf4nueHI\"\n",
    "openai_api_base = \"http://34.122.194.201:8000\"\n",
    "[11:13 PM, 9/23/2024] Eshan Gujar Genloop: if generating headlines, use this for system prompt: 'Generate a suitable headline for given input of a financial news article. Only output the headline not the instruction and input texts.'\n",
    "[11:15 PM, 9/23/2024] Eshan Gujar Genloop: and the model is: genloop/fin-news-headline-gen_mistral-nemo-instruct-merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry to hear that your car isn't starting. Here are some common troubleshooting steps you can take to identify the issue:\n",
      "\n",
      "1. **Check the Battery**:\n",
      "   - Ensure the battery terminals are clean and securely connected.\n",
      "   - Look for any signs of corrosion on the battery terminals.\n",
      "   - If you have a multimeter, check the battery voltage (should be around 12.6 volts when fully charged).\n",
      "\n",
      "2.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "openai_api_key = \"LOAD FROM ENV\"\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=openai_api_key\n",
    ")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model = \"gpt-4o-mini\",\n",
    "  messages = [ \n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"My car is not starting\"\n",
    "    }\n",
    "  ],\n",
    "  max_tokens = 85,\n",
    "  temperature = 0.7,\n",
    "  stream = False\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "from sqlalchemy import create_engine\n",
    "from psycopg2 import sql\n",
    "\n",
    "arena_df = pd.read_csv(\"arena_test_file.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Utility function to dynamically create a table using raw SQL\n",
    "# def create_table_from_csv_raw(table_name: str, df: pd.DataFrame):\n",
    "#     columns = []\n",
    "#     for column_name, dtype in zip(df.columns, df.dtypes):\n",
    "#         # Determine the SQL data type for each column\n",
    "#         if dtype == 'int64':\n",
    "#             columns.append(f\"{column_name} INTEGER\")\n",
    "#         elif dtype == 'float64':\n",
    "#             columns.append(f\"{column_name} FLOAT\")\n",
    "#         else:\n",
    "#             columns.append(f\"{column_name} TEXT\")\n",
    "    \n",
    "#     # SQL query to create a table\n",
    "#     create_table_query = f\"CREATE TABLE IF NOT EXISTS arenas.{table_name} ({', '.join(columns)});\"\n",
    "    \n",
    "#     # Connect to the database and execute the query\n",
    "#     with engine.connect() as connection:\n",
    "#         connection.execute(create_table_query)\n",
    "\n",
    "#         # Insert CSV data into the newly created table row by row\n",
    "#         for row in df.itertuples(index=False):\n",
    "#             values = tuple(row)\n",
    "#             insert_query = f\"INSERT INTO {table_name} VALUES {values};\"\n",
    "#             connection.execute(insert_query)\n",
    "\n",
    "# Utility function to dynamically create a table using raw SQL\n",
    "# from sqlalchemy import text\n",
    "\n",
    "# # Utility function to dynamically create a table using raw SQL\n",
    "# def create_table_from_csv_raw(table_name: str, df: pd.DataFrame):\n",
    "#     columns = []\n",
    "    \n",
    "#     # Create a mapping for pandas dtypes to SQL dtypes\n",
    "#     for column_name, dtype in zip(df.columns, df.dtypes):\n",
    "#         # Determine the SQL data type for each column\n",
    "#         if dtype == 'int64':\n",
    "#             columns.append(f\"{column_name} INTEGER\")\n",
    "#         elif dtype == 'float64':\n",
    "#             columns.append(f\"{column_name} FLOAT\")\n",
    "#         else:\n",
    "#             columns.append(f\"{column_name} TEXT\")\n",
    "    \n",
    "#     # SQL query to create a table within the 'arenas' schema\n",
    "#     create_table_query = f\"CREATE TABLE IF NOT EXISTS arenas.{table_name} ({', '.join(columns)});\"\n",
    "    \n",
    "#     # Connect to the database and execute the query\n",
    "#     with engine.connect() as connection:\n",
    "#         # Use the text() method to execute raw SQL\n",
    "#         connection.execute(text(create_table_query))\n",
    "\n",
    "#         # Prepare the insert query with placeholders\n",
    "#         placeholders = ', '.join(['%s'] * len(df.columns))\n",
    "#         insert_query = f\"INSERT INTO arenas.{table_name} VALUES ({placeholders});\"\n",
    "\n",
    "#         # Insert the CSV data into the newly created table row by row\n",
    "#         for row in df.itertuples(index=False, name=None):\n",
    "#             # Execute the insert query with parameterized values\n",
    "#             connection.execute(text(insert_query), row)\n",
    "\n",
    "\n",
    "# def create_table_from_csv_raw(table_name: str, df: pd.DataFrame):\n",
    "#     columns = []\n",
    "\n",
    "#     # Create a mapping for pandas dtypes to SQL dtypes\n",
    "#     for column_name, dtype in zip(df.columns, df.dtypes):\n",
    "#         if dtype == 'int64':\n",
    "#             columns.append(f\"{column_name} INTEGER\")\n",
    "#         elif dtype == 'float64':\n",
    "#             columns.append(f\"{column_name} FLOAT\")\n",
    "#         else:\n",
    "#             columns.append(f\"{column_name} TEXT\")\n",
    "\n",
    "#     # Create table query\n",
    "#     create_table_query = f\"CREATE TABLE IF NOT EXISTS arenas.{table_name} ({', '.join(columns)});\"\n",
    "\n",
    "#     # Connect to the database and execute the query\n",
    "#     with engine.connect() as connection:\n",
    "#         connection.execute(text(create_table_query))\n",
    "\n",
    "#         # Prepare the insert query with named placeholders\n",
    "#         named_placeholders = ', '.join([f\":{col}\" for col in df.columns])\n",
    "#         insert_query = f\"INSERT INTO arenas.{table_name} VALUES ({named_placeholders});\"\n",
    "\n",
    "#         # Insert the CSV data into the newly created table row by row\n",
    "#         for row in df.itertuples(index=False):\n",
    "#             params = {col: getattr(row, col) for col in df.columns}  # Create a dictionary\n",
    "#             connection.execute(text(insert_query), **params)  # Use named parameters\n",
    "\n",
    "\n",
    "# def create_table_from_csv_raw(engine, table_name: str, df: pd.DataFrame):\n",
    "#     columns = []\n",
    "\n",
    "#     # Create a mapping for pandas dtypes to SQL dtypes\n",
    "#     for column_name, dtype in zip(df.columns, df.dtypes):\n",
    "#         # Determine the SQL data type for each column\n",
    "#         if pd.api.types.is_integer_dtype(dtype):\n",
    "#             columns.append(f\"{column_name} INTEGER\")\n",
    "#         elif pd.api.types.is_float_dtype(dtype):\n",
    "#             columns.append(f\"{column_name} FLOAT\")\n",
    "#         else:\n",
    "#             columns.append(f\"{column_name} TEXT\")\n",
    "\n",
    "#     # Create table query\n",
    "#     create_table_query = f\"CREATE TABLE IF NOT EXISTS arenas.{table_name} ({', '.join(columns)});\"\n",
    "\n",
    "#     # Connect to the database and execute the query\n",
    "#     with engine.connect() as connection:\n",
    "#         connection.execute(text(create_table_query))\n",
    "\n",
    "#         # Prepare the insert query with named placeholders\n",
    "#         named_placeholders = ', '.join([f\":{col}\" for col in df.columns])\n",
    "#         insert_query = f\"INSERT INTO arenas.{table_name} ({', '.join(df.columns)}) VALUES ({named_placeholders});\"\n",
    "\n",
    "#         # Insert the DataFrame data into the newly created table\n",
    "#         for row in df.itertuples(index=False):\n",
    "#             params = {col: getattr(row, col) for col in df.columns}  # Create a dictionary\n",
    "#             connection.execute(text(insert_query), **params)  # Use named parameters\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "def create_table_from_csv_raw(engine, table_name: str, df: pd.DataFrame):\n",
    "    columns = []\n",
    "\n",
    "    # Create a mapping for pandas dtypes to SQL dtypes\n",
    "    for column_name, dtype in zip(df.columns, df.dtypes):\n",
    "        if pd.api.types.is_integer_dtype(dtype):\n",
    "            columns.append(f\"{column_name} INTEGER\")\n",
    "        elif pd.api.types.is_float_dtype(dtype):\n",
    "            columns.append(f\"{column_name} FLOAT\")\n",
    "        elif pd.api.types.is_bool_dtype(dtype):\n",
    "            columns.append(f\"{column_name} BOOLEAN\")\n",
    "        else:\n",
    "            columns.append(f\"{column_name} TEXT\")\n",
    "\n",
    "    # Create table query\n",
    "    create_table_query = f\"CREATE TABLE IF NOT EXISTS arenas.{table_name} ({', '.join(columns)});\"\n",
    "\n",
    "    # Connect to the database and execute the query\n",
    "    with engine.connect() as connection:\n",
    "        connection.execute(text(create_table_query))\n",
    "\n",
    "        # Prepare the insert query with named placeholders\n",
    "        named_placeholders = ', '.join([f\":{col}\" for col in df.columns])\n",
    "        insert_query = f\"INSERT INTO arenas.{table_name} ({', '.join(df.columns)}) VALUES ({named_placeholders});\"\n",
    "\n",
    "        # Insert the DataFrame data into the newly created table\n",
    "        for row in df.itertuples(index=False):\n",
    "            # Create a dictionary of row values\n",
    "            params = {col: getattr(row, col) for col in df.columns}\n",
    "            \n",
    "            # Convert any complex types (like dicts) to strings\n",
    "            for col, value in params.items():\n",
    "                if isinstance(value, dict):\n",
    "                    params[col] = str(value)  # Convert dict to string for SQL insertion\n",
    "\n",
    "            # Debugging: Print params to see what is being passed\n",
    "            print(f\"Inserting row: {params}\")\n",
    "            \n",
    "            # Execute the insert query\n",
    "            connection.execute(text(insert_query), **params)\n",
    "\n",
    "# Example usage\n",
    "# engine = create_engine('your_database_url')\n",
    "# create_table_from_csv_raw(engine, \"new_arena_table\", arena_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserting row: {'project_id': 'proj123', 'user_id': 'user001', 'call_id': 'call001', 'timestamp': '2024-07-01 08:05:00', 'input': 'input_data_1', 'output': 'output_data_1', 'model': 'modelA', 'cost': 12.5, 'latency': 0.2, 'meta': \"{'info': 'sample meta'}\", 'needs_review': True, 'correct_output': 'correct_output_1', 'did_user_correct': False}\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "execute() got an unexpected keyword argument 'project_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[91], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m engine \u001b[38;5;241m=\u001b[39m connect_tcp_socket()\n\u001b[0;32m----> 2\u001b[0m \u001b[43mcreate_table_from_csv_raw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnew_arena_table\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marena_df\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[90], line 162\u001b[0m, in \u001b[0;36mcreate_table_from_csv_raw\u001b[0;34m(engine, table_name, df)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInserting row: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparams\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    161\u001b[0m \u001b[38;5;66;03m# Execute the insert query\u001b[39;00m\n\u001b[0;32m--> 162\u001b[0m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m(\u001b[49m\u001b[43minsert_query\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: execute() got an unexpected keyword argument 'project_id'"
     ]
    }
   ],
   "source": [
    "engine = connect_tcp_socket()\n",
    "create_table_from_csv_raw(engine,\"new_arena_table\", arena_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arena_df\n",
    "len(arena_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserting row: {'project_id': 'proj123', 'user_id': 'user001', 'call_id': 'call001', 'timestamp': '2024-07-01 08:05:00', 'input': 'input_data_1', 'output': 'output_data_1', 'model': 'modelA', 'cost': 12.5, 'latency': 0.2, 'meta': \"{'info': 'sample meta'}\", 'needs_review': True, 'correct_output': 'correct_output_1', 'did_user_correct': False}\n",
      "Inserting row: {'project_id': 'proj124', 'user_id': 'user002', 'call_id': 'call002', 'timestamp': '2024-07-02 09:15:00', 'input': 'input_data_2', 'output': 'output_data_2', 'model': 'modelB', 'cost': 15.0, 'latency': 0.3, 'meta': \"{'info': 'sample meta'}\", 'needs_review': False, 'correct_output': 'correct_output_2', 'did_user_correct': True}\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine, text\n",
    "import pandas as pd\n",
    "\n",
    "def create_table_from_csv_raw(engine, table_name: str, df: pd.DataFrame):\n",
    "    columns = []\n",
    "    \n",
    "    # Map pandas dtypes to SQL dtypes\n",
    "    for column_name, dtype in zip(df.columns, df.dtypes):\n",
    "        if dtype == 'int64':\n",
    "            columns.append(f\"{column_name} INTEGER\")\n",
    "        elif dtype == 'float64':\n",
    "            columns.append(f\"{column_name} FLOAT\")\n",
    "        else:\n",
    "            columns.append(f\"{column_name} TEXT\")\n",
    "    \n",
    "    create_table_query = f\"CREATE TABLE IF NOT EXISTS arenas.{table_name} ({', '.join(columns)});\"\n",
    "    \n",
    "    with engine.connect() as connection:\n",
    "        connection.execution_options(isolation_level=\"AUTOCOMMIT\")    \n",
    "        connection.execute(text(create_table_query))\n",
    "        \n",
    "        # Prepare the insert query\n",
    "        placeholders = ', '.join([':' + col for col in df.columns])\n",
    "        insert_query = f\"INSERT INTO arenas.{table_name} ({', '.join(df.columns)}) VALUES ({placeholders});\"\n",
    "\n",
    "        # Insert data\n",
    "        for index, row in df.iterrows():\n",
    "            params = {col: row[col] for col in df.columns}  # Create a dictionary from the row\n",
    "            print(f\"Inserting row: {params}\")  # Debug output\n",
    "            connection.execute(text(insert_query), params)  # Pass params as a dictionary\n",
    "\n",
    "# Example usage\n",
    "create_table_from_csv_raw(engine, \"new_arena_table\", arena_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.9/3.9.10/Frameworks/Python.framework/Versions/3.9/lib/python3.9/encodings/utf_8.py:15\u001b[0m, in \u001b[0;36mdecode\u001b[0;34m(input, errors)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m### Codec APIs\u001b[39;00m\n\u001b[1;32m     13\u001b[0m encode \u001b[38;5;241m=\u001b[39m codecs\u001b[38;5;241m.\u001b[39mutf_8_encode\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28minput\u001b[39m, errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m codecs\u001b[38;5;241m.\u001b[39mutf_8_decode(\u001b[38;5;28minput\u001b[39m, errors, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mIncrementalEncoder\u001b[39;00m(codecs\u001b[38;5;241m.\u001b[39mIncrementalEncoder):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "OperationalError",
     "evalue": "(psycopg2.OperationalError) could not receive data from server: Operation timed out\nSSL SYSCALL error: Operation timed out\n\n[SQL: \n    INSERT INTO dataset_hub (dataset_id, dataset_name, dataset_comment, created_at, rows, model_ids, lineage, table_path, project_id)\n    VALUES ('temp_954', 'temp_954', 'temp', '2024-09-21 22:02:12.737431', 2, '{temp}', '{\"temp\" : \"temp\"}', 'temp', '001');\n]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/sqlalchemy/engine/base.py:1967\u001b[0m, in \u001b[0;36mConnection._exec_single_context\u001b[0;34m(self, dialect, context, statement, parameters)\u001b[0m\n\u001b[1;32m   1966\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evt_handled:\n\u001b[0;32m-> 1967\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_execute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1968\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstr_statement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meffective_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[1;32m   1969\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1971\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_events \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39m_has_events:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/sqlalchemy/engine/default.py:924\u001b[0m, in \u001b[0;36mDefaultDialect.do_execute\u001b[0;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdo_execute\u001b[39m(\u001b[38;5;28mself\u001b[39m, cursor, statement, parameters, context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 924\u001b[0m     \u001b[43mcursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOperationalError\u001b[0m: could not receive data from server: Operation timed out\nSSL SYSCALL error: Operation timed out\n",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[112], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m test_query \u001b[38;5;241m=\u001b[39m text(\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124m    INSERT INTO dataset_hub (dataset_id, dataset_name, dataset_comment, created_at, rows, model_ids, lineage, table_path, project_id)\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124m    VALUES (\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtemp_954\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtemp_954\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtemp\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2024-09-21 22:02:12.737431\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, 2, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{temp}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemp\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m : \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemp\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m}\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtemp\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m001\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m);\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m engine\u001b[38;5;241m.\u001b[39mconnect() \u001b[38;5;28;01mas\u001b[39;00m connection:\n\u001b[0;32m----> 7\u001b[0m     \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_query\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/sqlalchemy/engine/base.py:1418\u001b[0m, in \u001b[0;36mConnection.execute\u001b[0;34m(self, statement, parameters, execution_options)\u001b[0m\n\u001b[1;32m   1416\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mObjectNotExecutableError(statement) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   1417\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1419\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1420\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdistilled_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1421\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mNO_OPTIONS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1422\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/sqlalchemy/sql/elements.py:515\u001b[0m, in \u001b[0;36mClauseElement._execute_on_connection\u001b[0;34m(self, connection, distilled_params, execution_options)\u001b[0m\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n\u001b[1;32m    514\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, Executable)\n\u001b[0;32m--> 515\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_clauseelement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    516\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdistilled_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecution_options\u001b[49m\n\u001b[1;32m    517\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    519\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mObjectNotExecutableError(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/sqlalchemy/engine/base.py:1640\u001b[0m, in \u001b[0;36mConnection._execute_clauseelement\u001b[0;34m(self, elem, distilled_parameters, execution_options)\u001b[0m\n\u001b[1;32m   1628\u001b[0m compiled_cache: Optional[CompiledCacheType] \u001b[38;5;241m=\u001b[39m execution_options\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m   1629\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompiled_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39m_compiled_cache\n\u001b[1;32m   1630\u001b[0m )\n\u001b[1;32m   1632\u001b[0m compiled_sql, extracted_params, cache_hit \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39m_compile_w_cache(\n\u001b[1;32m   1633\u001b[0m     dialect\u001b[38;5;241m=\u001b[39mdialect,\n\u001b[1;32m   1634\u001b[0m     compiled_cache\u001b[38;5;241m=\u001b[39mcompiled_cache,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1638\u001b[0m     linting\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdialect\u001b[38;5;241m.\u001b[39mcompiler_linting \u001b[38;5;241m|\u001b[39m compiler\u001b[38;5;241m.\u001b[39mWARN_LINTING,\n\u001b[1;32m   1639\u001b[0m )\n\u001b[0;32m-> 1640\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_context\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1641\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1642\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecution_ctx_cls\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_compiled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1643\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompiled_sql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1644\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistilled_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1645\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1646\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompiled_sql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1647\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistilled_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1648\u001b[0m \u001b[43m    \u001b[49m\u001b[43melem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1649\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextracted_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1650\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_hit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_hit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1651\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_events:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch\u001b[38;5;241m.\u001b[39mafter_execute(\n\u001b[1;32m   1654\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1655\u001b[0m         elem,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1659\u001b[0m         ret,\n\u001b[1;32m   1660\u001b[0m     )\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/sqlalchemy/engine/base.py:1846\u001b[0m, in \u001b[0;36mConnection._execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[1;32m   1844\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exec_insertmany_context(dialect, context)\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1846\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_exec_single_context\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1847\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\n\u001b[1;32m   1848\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/sqlalchemy/engine/base.py:1986\u001b[0m, in \u001b[0;36mConnection._exec_single_context\u001b[0;34m(self, dialect, context, statement, parameters)\u001b[0m\n\u001b[1;32m   1983\u001b[0m     result \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39m_setup_result_proxy()\n\u001b[1;32m   1985\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 1986\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_dbapi_exception\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1987\u001b[0m \u001b[43m        \u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstr_statement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meffective_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[1;32m   1988\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1990\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/sqlalchemy/engine/base.py:2353\u001b[0m, in \u001b[0;36mConnection._handle_dbapi_exception\u001b[0;34m(self, e, statement, parameters, cursor, context, is_sub_exec)\u001b[0m\n\u001b[1;32m   2351\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m should_wrap:\n\u001b[1;32m   2352\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m sqlalchemy_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 2353\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m sqlalchemy_exception\u001b[38;5;241m.\u001b[39mwith_traceback(exc_info[\u001b[38;5;241m2\u001b[39m]) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m   2354\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2355\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m exc_info[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/sqlalchemy/engine/base.py:1967\u001b[0m, in \u001b[0;36mConnection._exec_single_context\u001b[0;34m(self, dialect, context, statement, parameters)\u001b[0m\n\u001b[1;32m   1965\u001b[0m                 \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   1966\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evt_handled:\n\u001b[0;32m-> 1967\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_execute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1968\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstr_statement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meffective_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[1;32m   1969\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1971\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_events \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39m_has_events:\n\u001b[1;32m   1972\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch\u001b[38;5;241m.\u001b[39mafter_cursor_execute(\n\u001b[1;32m   1973\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1974\u001b[0m         cursor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1978\u001b[0m         context\u001b[38;5;241m.\u001b[39mexecutemany,\n\u001b[1;32m   1979\u001b[0m     )\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/sqlalchemy/engine/default.py:924\u001b[0m, in \u001b[0;36mDefaultDialect.do_execute\u001b[0;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdo_execute\u001b[39m(\u001b[38;5;28mself\u001b[39m, cursor, statement, parameters, context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 924\u001b[0m     \u001b[43mcursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOperationalError\u001b[0m: (psycopg2.OperationalError) could not receive data from server: Operation timed out\nSSL SYSCALL error: Operation timed out\n\n[SQL: \n    INSERT INTO dataset_hub (dataset_id, dataset_name, dataset_comment, created_at, rows, model_ids, lineage, table_path, project_id)\n    VALUES ('temp_954', 'temp_954', 'temp', '2024-09-21 22:02:12.737431', 2, '{temp}', '{\"temp\" : \"temp\"}', 'temp', '001');\n]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)"
     ]
    }
   ],
   "source": [
    "test_query = text(\"\"\"\n",
    "    INSERT INTO dataset_hub (dataset_id, dataset_name, dataset_comment, created_at, rows, model_ids, lineage, table_path, project_id)\n",
    "    VALUES ('temp_954', 'temp_954', 'temp', '2024-09-21 22:02:12.737431', 2, '{temp}', '{\"temp\" : \"temp\"}', 'temp', '001');\n",
    "\"\"\")\n",
    "\n",
    "with engine.connect() as connection:\n",
    "    connection.execute(test_query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    INSERT INTO dataset_hub (dataset_id, dataset_name, dataset_comment, created_at, rows, model_ids, lineage, table_path, project_id)\n",
      "    VALUES (:dataset_id, :dataset_name, :dataset_comment, :created_at, :rows, :model_ids, :lineage, :table_path, :project_id);\n",
      "     {'dataset_id': 'datas2et_id', 'dataset_name': 'dataset_name', 'dataset_comment': 'comment', 'created_at': 'created_at', 'rows': 2, 'model_ids': '[\"temp\"]', 'lineage': '{\"temp\" : \"temp\"}', 'table_path': None, 'project_id': '001'}\n",
      "Error inserting dataset entry: execute() got an unexpected keyword argument 'dataset_id'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from sqlalchemy.exc import SQLAlchemyError\n",
    "\n",
    "def insert_dataset_entry(engine, dataset_id, dataset_name, dataset_comment, created_at, rows, model_ids= {'temp'}, lineage =  '{\"temp\" : \"temp\"}', table_path=None, project_id = '001'):\n",
    "    # Define the SQL insert query\n",
    "    insert_query = \"\"\"\n",
    "    INSERT INTO dataset_hub (dataset_id, dataset_name, dataset_comment, created_at, rows, model_ids, lineage, table_path, project_id)\n",
    "    VALUES (:dataset_id, :dataset_name, :dataset_comment, :created_at, :rows, :model_ids, :lineage, :table_path, :project_id);\n",
    "    \"\"\"\n",
    "    \n",
    "    # Prepare parameters for the query\n",
    "    params = {\n",
    "        \"dataset_id\": dataset_id,\n",
    "        \"dataset_name\": dataset_name,\n",
    "        \"dataset_comment\": dataset_comment,\n",
    "        \"created_at\": created_at,\n",
    "        \"rows\": rows,\n",
    "        \"model_ids\": json.dumps(list(model_ids)),\n",
    "        \"lineage\": lineage,\n",
    "        \"table_path\": table_path,\n",
    "        \"project_id\": project_id\n",
    "    }\n",
    "    try:\n",
    "        with engine.connect() as connection:\n",
    "            # connection.execution_options(isolation_level=\"AUTOCOMMIT\")    \n",
    "            print(insert_query, params)\n",
    "            \n",
    "            connection.execute(text(insert_query), **params)\n",
    "            print(\"Dataset entry inserted successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error inserting dataset entry: {e}\")\n",
    "        \n",
    "\n",
    "insert_dataset_entry(engine, \"datas2et_id\", \"dataset_name\", \"comment\", \"created_at\", 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
